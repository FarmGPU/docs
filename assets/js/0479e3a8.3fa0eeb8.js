"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9868],{929:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/network_ns-9a33760b250302fa3b50ab63230ebe72.jpg"},2348:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"networking","title":"Networking Technology in AI Data Centers","description":"The choice of networking fabric is a critical differentiator for AI data centers, impacting performance, scalability, and cost.","source":"@site/ai-datacenter/5_networking.md","sourceDirName":".","slug":"/networking","permalink":"/ai-datacenter/networking","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Hardware and Component Specialization","permalink":"/ai-datacenter/hardware"},"next":{"title":"Power and Electrical","permalink":"/ai-datacenter/power"}}');var r=n(4848),s=n(8453);const l={sidebar_position:5},a="Networking Technology in AI Data Centers",o={},c=[{value:"Networking Technology Comparison",id:"networking-technology-comparison",level:2},{value:"Visualizing AI Data Center Networking",id:"visualizing-ai-data-center-networking",level:2},{value:"System-Level Optimization",id:"system-level-optimization",level:2},{value:"Economic Impact of Networking Choices",id:"economic-impact-of-networking-choices",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const t={admonition:"admonition",blockquote:"blockquote",em:"em",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"networking-technology-in-ai-data-centers",children:"Networking Technology in AI Data Centers"})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"The choice of networking fabric is a critical differentiator for AI data centers, impacting performance, scalability, and cost."}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"networking-technology-comparison",children:"Networking Technology Comparison"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{style:{textAlign:"left"},children:"Technology"}),(0,r.jsx)(t.th,{style:{textAlign:"left"},children:"Key Characteristics"}),(0,r.jsx)(t.th,{style:{textAlign:"left"},children:"Primary Use Case (AI DC)"}),(0,r.jsx)(t.th,{style:{textAlign:"left"},children:"Pros"}),(0,r.jsx)(t.th,{style:{textAlign:"left"},children:"Cons"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{style:{textAlign:"left"},children:(0,r.jsx)(t.strong,{children:"Standard Ethernet (\u2264100G)"})}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Ubiquitous, best-effort delivery, mature ecosystem, lower speeds"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Frontend network, management, traditional workloads"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Cost-effective, widely understood, interoperable"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"High latency, not lossless (unsuitable for RDMA/AI collectives without significant modification)"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{style:{textAlign:"left"},children:(0,r.jsx)(t.strong,{children:"InfiniBand (IB)"})}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"High bandwidth (400G/800G+), low latency, lossless fabric, native RDMA support"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"AI training backend fabric (Scale-Out)"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Proven performance for HPC/AI, efficient RDMA, mature ecosystem for HPC"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Potential scaling limits, higher cost, vendor concentration (NVIDIA/Mellanox), separate network"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{style:{textAlign:"left"},children:(0,r.jsx)(t.strong,{children:"Ethernet with RoCE (e.g., Spectrum-X)"})}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"High bandwidth (400G/800G+), RDMA over Ethernet, requires lossless configuration (PFC/ECN)"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"AI training/inference backend fabric (Scale-Out)"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Leverages Ethernet ecosystem, potential cost savings, supplier diversity, better integration potential"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Requires careful configuration for losslessness, performance potentially sensitive to network tuning"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{style:{textAlign:"left"},children:(0,r.jsx)(t.strong,{children:"Scale-Up Fabric (NVLink/ICI/NeuronLink)"})}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Extremely high bandwidth (TB/s aggregate), ultra-low latency, proprietary, short reach"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Intra-server/intra-node accelerator interconnect (Scale-Up)"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Enables fine-grained parallelism (e.g., tensor parallelism), maximizes accelerator utilization"}),(0,r.jsx)(t.td,{style:{textAlign:"left"},children:"Proprietary, limited distance, adds complexity/cost"})]})]})]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"visualizing-ai-data-center-networking",children:"Visualizing AI Data Center Networking"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"North/South Network Diagram",src:n(929).A+"",width:"960",height:"540"}),"\n",(0,r.jsx)(t.em,{children:"Figure: North/South (NS) network traffic in a data center, typically representing traffic between external clients and internal servers."})]}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"East/West Network Diagram",src:n(4752).A+"",width:"960",height:"540"}),"\n",(0,r.jsx)(t.em,{children:"Figure: East/West (EW) network traffic in a data center, representing traffic between servers or racks within the data center, crucial for distributed AI workloads."})]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"system-level-optimization",children:"System-Level Optimization"}),"\n",(0,r.jsx)(t.admonition,{type:"info",children:(0,r.jsx)(t.p,{children:"AI data centers foster a much tighter coupling between accelerators, memory, and interconnect compared to traditional, modular server designs."})}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Traditional servers allow flexible mixing of CPUs, DRAM, NICs, and storage."}),"\n",(0,r.jsx)(t.li,{children:"AI servers require balanced throughput across the entire data path (HBM \u2192 accelerator \u2192 interconnect)."}),"\n",(0,r.jsx)(t.li,{children:"Bottlenecks in memory or networking can leave expensive compute units underutilized."}),"\n",(0,r.jsx)(t.li,{children:"System-level co-design is emphasized (e.g., NVIDIA DGX, Google TPU pods, AWS Trainium servers)."}),"\n"]}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:'"AI server design increasingly emphasizes system-level optimization and co-design, contrasting sharply with the component-level modularity of traditional servers."'}),"\n"]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"economic-impact-of-networking-choices",children:"Economic Impact of Networking Choices"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Shift from general-purpose CPUs to specialized accelerators reshapes the data center value chain."}),"\n",(0,r.jsx)(t.li,{children:"In high-end AI servers, accelerators dominate the cost structure; DRAM is a much smaller fraction."}),"\n",(0,r.jsx)(t.li,{children:"Suppliers of HBM and high-speed interconnects gain importance; traditional CPU/DRAM vendors see relative decline."}),"\n",(0,r.jsx)(t.li,{children:"Networking technology choice (InfiniBand vs. RoCE) impacts both performance and economics."}),"\n"]}),"\n",(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsx)(t.p,{children:"The ongoing competition between InfiniBand and high-speed Ethernet (RoCE) is driving innovation and providing customers with more choices for large-scale AI deployments."})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"\"Ethernet's ubiquity and cost base make it attractive for hyperscalers, while InfiniBand's low-latency, lossless design remains proven for tightly coupled AI workloads.\""}),"\n"]}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"AI data centers require specialized, high-bandwidth, low-latency networking fabrics."}),"\n",(0,r.jsx)(t.li,{children:"System-level co-design is critical for maximizing accelerator utilization."}),"\n",(0,r.jsx)(t.li,{children:"The choice between InfiniBand and RoCE is a major architectural and economic decision."}),"\n",(0,r.jsx)(t.li,{children:"Networking innovation is accelerating as AI workloads scale up."}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},4752:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/network_ew-8834ebaae15f1793e6192d08b90300ed.jpg"},8453:(e,t,n)=>{n.d(t,{R:()=>l,x:()=>a});var i=n(6540);const r={},s=i.createContext(r);function l(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);